{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Contents:</center><a class=\"anchor\" id=\"contents\"></a>\n",
    "\n",
    "1. [Synthesize data](#synthesize)\n",
    "\n",
    "*1.1. Create random DataFrame*\n",
    "\n",
    "*1.2. insert 10% NaN values to DataFrame*\n",
    "\n",
    "*1.3. Function to add column with random text*\n",
    "\n",
    "*1.4. Create column for cohorts*\n",
    "\n",
    "\n",
    "2. [Read & Import, merge, join, concatenate](#import)\n",
    "\n",
    "*2.1. Glue few tables to one*\n",
    "\n",
    "3. [Analysis](#analysis)\n",
    "\n",
    "4. [Computing acceleration and preprocessing](#preprocessing)\n",
    "\n",
    "5. [Other](#other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize data\n",
    "<a class=\"anchor\" id=\"synthesize\"></a>\n",
    "\n",
    "[оглавление](#contents) | [дальше>](#import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Create random DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>50.108</td>\n",
       "      <td>29.049134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>50.455</td>\n",
       "      <td>28.703865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>50.436</td>\n",
       "      <td>29.381715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>49.482</td>\n",
       "      <td>28.191673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count    mean        std  min   25%   50%   75%   max\n",
       "a  1000.0  50.108  29.049134  0.0  25.0  49.0  77.0  99.0\n",
       "b  1000.0  50.455  28.703865  0.0  26.0  51.0  75.0  99.0\n",
       "c  1000.0  50.436  29.381715  0.0  25.0  52.5  77.0  99.0\n",
       "d  1000.0  49.482  28.191673  0.0  25.0  50.0  74.0  99.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df = pd.DataFrame(np.random.randint(0, 100, size=(1000, 4)),\n",
    "                                 columns=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# random_created_df.info()\n",
    "random_created_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Insert 10% NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>915.0</td>\n",
       "      <td>49.397814</td>\n",
       "      <td>29.060926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>896.0</td>\n",
       "      <td>50.549107</td>\n",
       "      <td>28.685773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>51.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>896.0</td>\n",
       "      <td>50.768973</td>\n",
       "      <td>29.203872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.75</td>\n",
       "      <td>53.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>910.0</td>\n",
       "      <td>49.774725</td>\n",
       "      <td>28.384109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       mean        std  min    25%   50%   75%   max\n",
       "a  915.0  49.397814  29.060926  0.0  24.00  48.0  76.0  99.0\n",
       "b  896.0  50.549107  28.685773  0.0  26.00  51.5  75.0  99.0\n",
       "c  896.0  50.768973  29.203872  0.0  25.75  53.0  77.0  99.0\n",
       "d  910.0  49.774725  28.384109  0.0  25.00  50.0  74.0  99.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df = random_created_df.mask(np.random.random(random_created_df.shape) < .1)\n",
    "\n",
    "# random_created_df.info()\n",
    "random_created_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Function to add column with random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def function_to_apply(i):\n",
    "    first = requests.get(f'https://random-word-api.herokuapp.com/word').json() # Random Word API\n",
    "    \n",
    "#     add word\n",
    "#     second = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "#     third = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "\n",
    "    return first[0]\n",
    "#     return \" \".join([first[0], second[0], third[0]])\n",
    "\n",
    "random_created_df['words'] = random_created_df['d'].apply(function_to_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>915.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.397814</td>\n",
       "      <td>29.060926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.549107</td>\n",
       "      <td>28.685773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.768973</td>\n",
       "      <td>29.203872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.75</td>\n",
       "      <td>53.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.774725</td>\n",
       "      <td>28.384109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>1000</td>\n",
       "      <td>998</td>\n",
       "      <td>roseslug</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count unique       top freq       mean        std  min    25%   50%  \\\n",
       "a      915.0    NaN       NaN  NaN  49.397814  29.060926  0.0   24.0  48.0   \n",
       "b      896.0    NaN       NaN  NaN  50.549107  28.685773  0.0   26.0  51.5   \n",
       "c      896.0    NaN       NaN  NaN  50.768973  29.203872  0.0  25.75  53.0   \n",
       "d      910.0    NaN       NaN  NaN  49.774725  28.384109  0.0   25.0  50.0   \n",
       "words   1000    998  roseslug    2        NaN        NaN  NaN    NaN   NaN   \n",
       "\n",
       "        75%   max  \n",
       "a      76.0  99.0  \n",
       "b      75.0  99.0  \n",
       "c      77.0  99.0  \n",
       "d      74.0  99.0  \n",
       "words   NaN   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Create column for cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col         = 'a'\n",
    "conditions  = [ random_created_df[col] >= 65, (random_created_df[col] < 65) & (random_created_df[col] >= 40), random_created_df[col] < 40 ]\n",
    "choices     = [ '65>', '40-65', '<40' ]\n",
    "    \n",
    "random_created_df['cohort'] = np.select(conditions, choices, default=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>915.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.397814</td>\n",
       "      <td>29.060926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.549107</td>\n",
       "      <td>28.685773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.768973</td>\n",
       "      <td>29.203872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.75</td>\n",
       "      <td>53.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.774725</td>\n",
       "      <td>28.384109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>1000</td>\n",
       "      <td>998</td>\n",
       "      <td>roseslug</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;40</td>\n",
       "      <td>377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count unique       top freq       mean        std  min    25%   50%  \\\n",
       "a       915.0    NaN       NaN  NaN  49.397814  29.060926  0.0   24.0  48.0   \n",
       "b       896.0    NaN       NaN  NaN  50.549107  28.685773  0.0   26.0  51.5   \n",
       "c       896.0    NaN       NaN  NaN  50.768973  29.203872  0.0  25.75  53.0   \n",
       "d       910.0    NaN       NaN  NaN  49.774725  28.384109  0.0   25.0  50.0   \n",
       "words    1000    998  roseslug    2        NaN        NaN  NaN    NaN   NaN   \n",
       "cohort   1000      4       <40  377        NaN        NaN  NaN    NaN   NaN   \n",
       "\n",
       "         75%   max  \n",
       "a       76.0  99.0  \n",
       "b       75.0  99.0  \n",
       "c       77.0  99.0  \n",
       "d       74.0  99.0  \n",
       "words    NaN   NaN  \n",
       "cohort   NaN   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>words</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>varicosed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>serotonergic</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beautician</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>centerfolds</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>handstamp</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>deodorize</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>lammergeyers</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>restock</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>aimlessnesses</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>newbies</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a     b     c     d          words cohort\n",
       "21  NaN  10.0  58.0  83.0      varicosed    nan\n",
       "29  NaN  30.0  85.0  58.0   serotonergic    nan\n",
       "35  NaN  60.0  43.0   NaN     beautician    nan\n",
       "45  NaN  31.0  42.0  37.0    centerfolds    nan\n",
       "54  NaN  24.0  15.0  36.0      handstamp    nan\n",
       "..   ..   ...   ...   ...            ...    ...\n",
       "970 NaN  38.0  24.0  80.0      deodorize    nan\n",
       "975 NaN  81.0  17.0  17.0   lammergeyers    nan\n",
       "982 NaN   NaN   NaN  47.0        restock    nan\n",
       "984 NaN  22.0  23.0  41.0  aimlessnesses    nan\n",
       "990 NaN  58.0  23.0  13.0        newbies    nan\n",
       "\n",
       "[85 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df[random_created_df['cohort'] == 'nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Import, merge, join, concatenate\n",
    "<a class=\"anchor\" id=\"import\"></a>\n",
    "\n",
    "[оглавление](#contents) | [дальше>](#join)\n",
    "\n",
    "Some topics:\n",
    "\n",
    "[Работа с большими наборами данных](https://habr.com/ru/company/ruvds/blog/442516/)\n",
    "\n",
    "[Управление памятью](https://habr.com/ru/company/mailru/blog/336156/)\n",
    "\n",
    "[How upload to notebook files from github (medium.com)](https://medium.com/towards-entrepreneurship/importing-a-csv-file-from-github-in-a-jupyter-notebook-e2c28e7e74a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Glue few tables to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# показать путь к текщей директории\n",
    "os.getcwd()\n",
    "\n",
    "# указываем путь к папке с файлами, которые хотим объединить\n",
    "\n",
    "folder = r'C:\\\\Users\\\\Asus\\\\GKU\\\\2505\\\\all_audio' # insert abs path\n",
    "\n",
    "# создаем список с названиями файлов\n",
    "files_names = os.listdir(folder)\n",
    "\n",
    "#формируем список путей к файлам\n",
    "files = [os.path.join(folder,f) for f in files_names] \n",
    "\n",
    "all_file_frames = [] #сюда будем добавлять прочитанную таблицу \n",
    "\n",
    "# цикл сборки таблиц в список\n",
    "for f in files:\n",
    "    print('Reading %s'%f)\n",
    "    tab = pd.read_excel(f)\n",
    "    all_file_frames.append(tab)\n",
    "\n",
    "# склеиваем все таблицы в списке\n",
    "all_frame = pd.concat(all_file_frames,axis=0) #  axis=0 если нужно добавить таблицу снизу и axis=1 если нужно слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Pandas Column Names to Lower Case\n",
    "\n",
    "df= df.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "<a class=\"anchor\" id=\"analysis\"></a>\n",
    "\n",
    "[<назад](#join) | [оглавление](#contents) | [дальше>](#preprocessing)\n",
    "\n",
    "Some topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "см. также Чтение и быстрое преобразование данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create custom describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк в наборе данных: 100000\n",
      "\n",
      "10% - доля пропусков в столбце c\n",
      "9% - доля пропусков в столбце d\n",
      "9% - доля пропусков в столбце a\n",
      "9% - доля пропусков в столбце b\n"
     ]
    }
   ],
   "source": [
    "w_df = random_created_df.copy()\n",
    "\n",
    "show_percent_dict = {}\n",
    "\n",
    "for _ in w_df.columns.tolist():\n",
    "    percent = (w_df[w_df[_].isna()].shape[0] / w_df.shape[0]) * 100\n",
    "    show_percent_dict[_] = percent\n",
    "\n",
    "show_percent_dict = dict(sorted(show_percent_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "print(f'Всего строк в наборе данных: {w_df.shape[0]}\\n')\n",
    "\n",
    "for k,v in show_percent_dict.items():  \n",
    "    v = str(int(v)) + '%'\n",
    "    print(f'{v} - доля пропусков в столбце {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing acceleration and preprocessing\n",
    "<a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "[<назад](#analysis) | [оглавление](#contents)\n",
    "\n",
    "Some topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    998\n",
       "True       2\n",
       "Name: equal 4th, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find rows with equal values\n",
    "random_created_df['equal 4th'] =  random_created_df.iloc[:,0:5].nunique(axis = 1).eq(1)\n",
    "random_created_df['equal 4th'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some values to  1\n",
    "\n",
    "for n in list(range(1,1001)):\n",
    "    if n % 5 == 0:\n",
    "        random_created_df.loc[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    800\n",
       "True     201\n",
       "Name: equal 4th, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df['equal 4th'] =  random_created_df.iloc[:,0:5].nunique(axis = 1).eq(1)\n",
    "random_created_df['equal 4th'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [about `replace` and `map` vs replace](https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict-preserve-nans)\n",
    "\n",
    "If your dictionary has more than a couple of keys, using map can be much faster than replace. There are two versions of this approach, depending on whether your dictionary exhaustively maps all possible values (and also whether you want non-matches to keep their values or be converted to NaNs):\n",
    "\n",
    "\n",
    "example with binary features^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всем добрый день!\n",
    "# Помогите решить задачку. Имею следующий формат учета продаж.\n",
    "# Необходимо посчитать тотал по каждому клиенту. \n",
    "# В Power Query задачку решил, в питоне не получается.\n",
    "\n",
    "\n",
    "# df = pd.read_excel('/.../Новая таблица.xlsx')\n",
    "# pd.DataFrame.from_records(\n",
    "#     df.apply(lambda x: {value:x[idx+1] for idx, (col_name, value) in enumerate(zip(df.columns, x)) if 'customer' in col_name.lower()}, axis=1).values\n",
    "#     ).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.eq(report.iloc[:,5:10], axis=0).all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение и быстрое преобразование данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. `value_counts` и `select_dtypes` сэкономит кучу времени:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `df.dtypes.value_counts()`\n",
    "\n",
    "\n",
    "* `df.select_dtypes(include = ['float64', 'int64'])`\n",
    "\n",
    "Полезные аргументы `value_counts`:\n",
    "\n",
    "* `normalize = True` – проверить частоту вместо подсчёта.\n",
    "\n",
    "\n",
    "* `dropna = False` – включить пропущенные значения в статистику.\n",
    "\n",
    "\n",
    "* `df['c'].value_counts().reset_index()` – преобразовать таблицу статистики в объект Pandas DataFrame.\n",
    "\n",
    "\n",
    "* `df['c'].value_counts().reset_index().sort_values(by='index')` – показывать статистику, отсортированную по уникальным значениям в столбце 'c' вместо количества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `map` - команда для простого преобразования данных.\n",
    "Определяете словарь, в котором «ключами» являются старые значения, а «значениями» – новые значения:\n",
    "\n",
    "`level_map = {1: 'high', 2: 'medium', 3: 'low'}`\n",
    "\n",
    "`df['c_level'] = df['c'].map(level_map)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Как это использовать?</font>\n",
    "\n",
    "`all_doc.applymap(type)['BIRTH_DATE'].value_counts()\n",
    "bad = all_doc[all_doc['BIRTH_DATE'].map(lambda x: type(x) == str)]\n",
    "good = all_doc[all_doc['BIRTH_DATE'].map(lambda x: type(x) != str)]\n",
    "all_doc_2 = bad.append(good, ignore_index=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.  Выборка и фильтрация:\n",
    "\n",
    "конечно можно решать задачи через `loc` `iloc`\n",
    "\n",
    "`data.loc[:,\"User\"]`\n",
    "\n",
    "`data.iloc[:5,0]`\n",
    "\n",
    "В SQL используем SELECT * FROM… WHERE ID в («A001», «C022»,…) и получаем записи с конкретными идентификаторами. Если хотите сделать то же с помощью Python библиотеки Pandas, используйте:\n",
    "\n",
    "\n",
    "`df_filter = df['ID'].isin(['A001','C022',...])`\n",
    "\n",
    "`df[df_filter]`\n",
    "\n",
    "\n",
    "#### 3.2. [numpy.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html) для работы со значениями:\n",
    "\n",
    "`numpy.where(data['Revenue']>400,1,0)`\n",
    "\n",
    "`numpy.where(data['Revenue']<data['Expense'],1,2)`\n",
    "\n",
    "#### [3.3. Еще 3 полезных метода](https://m.habr.com/ru/company/ruvds/blog/479276/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. `datetime` processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to date from string\n",
    "\n",
    "# нормализуем и форматируем все даты\n",
    "datecols = [col for col in pp.columns if re.search('(?i)Дат(а|у)', col)]\n",
    "gooddatecols = []\n",
    "baddatecols = []\n",
    "for datecol in datecols:\n",
    "  if pp[datecol].dtypes == 'datetime64[ns]':\n",
    "    gooddatecols.append(datecol)\n",
    "  else:\n",
    "    baddatecols.append(datecol)\n",
    "    \n",
    "def normalize_date(series):\n",
    "  def trydate(arg):\n",
    "    try:\n",
    "      if pd.isna(arg): return pd.NaT\n",
    "      if type(arg) == datetime.datetime:\n",
    "        return pd.to_datetime(arg).normalize()\n",
    "      elif type(arg) == str:\n",
    "        match = re.search(r'\\d{2}(.)\\d{2}\\1\\d{4}', arg)\n",
    "        if match:\n",
    "          delimiter = match.group(1)\n",
    "          try: return pd.to_datetime(match.group(), format=f'%d{delimiter}%m{delimiter}%Y')\n",
    "          except: return False\n",
    "        else: return arg\n",
    "    except: \n",
    "      return False\n",
    "  if series.name in gooddatecols:\n",
    "    return series.dt.normalize()\n",
    "  else:\n",
    "    return series.apply(trydate)\n",
    "\n",
    "for datecol in datecols:\n",
    "  pp[datecol] = normalize_date(pp[datecol])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "for _ in all_frame.columns.tolist():\n",
    "    if 'Дата' in _:\n",
    "        all_frame[_] = pd.to_datetime(all_frame[_], errors='ignore') \n",
    "\n",
    "all_frame.to_excel(f'направления_к_онколгу_из_облака_BD_1194_на_ОТ_РАЗРАБОВ_{today}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date formatting\n",
    "# everytime check?????????????????????????????????????????????\n",
    "\n",
    "# = '2020-01-15'\n",
    "first_date_type_list = ['Биопсия - Дата проведения биопсии',\n",
    "                        'Специализированное лечение - Плановая дата проведения лекарственного лечения']\n",
    "\n",
    "# = '1997-04-05 00:00:00'\n",
    "dob = ['общая информация - ДР пациента']\n",
    "\n",
    "# = '1997-04-05T00:00:00+04:00'\n",
    "second_date_type_list = ['общая информация - Дата и время подписания протокола',\n",
    "                         'Считает себя больным с ',\n",
    "                        'Диагноз - Дата устанвоки диагноза',\n",
    "                        'Новый диагноз - Дата установления нового диагноза',\n",
    "                        'Онкоконсилиум - Плановая дата проведения онкоконсилиума',                         \n",
    "                        'Вложенный диагноз на первичном приеме (1) - Дата установления диагноза',\n",
    "                        'Вложенный диагноз на первичном приеме (2) - Дата установления диагноза',\n",
    "                        'Вложенный диагноз на первичном приеме (3) - Дата установления диагноза',\n",
    "                        'Вложенный диагноз на первичном приеме (4) - Дата установления диагноза',\n",
    "                        'Множественная опухоль(1) - Дата установления диагноза', \n",
    "                        # понять почему остался постфикс в конце\n",
    "                        'Множественная опухоль(2) - Дата установления диагноза',\n",
    "                        'Множественная опухоль(3) - Дата установления диагноза',\n",
    "                        'Множественная опухоль(4) - Дата установления диагноза']\n",
    "\n",
    "date_cols = first_date_type_list+dob+second_date_type_list\n",
    "\n",
    "# check ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "total_data[date_cols].sample(10)\n",
    "# total_data[date_cols].info()\n",
    "\n",
    "%%time\n",
    "total_data_copy = total_data.copy()\n",
    "\n",
    "for _ in total_data_copy.columns.tolist():\n",
    "    if _ in date_cols:\n",
    "        total_data_copy[_] = total_data_copy[_].fillna(pd.NaT)\n",
    "        if _ == 'общая информация - ДР пациента':\n",
    "            total_data_copy[_] = pd.to_datetime(total_data_copy[_], format = '%Y-%m-%d %H:%M:%S', errors='ignore').dt.date\n",
    "        elif _ in second_date_type_list:\n",
    "            total_data_copy[_] = total_data_copy[_].str.replace(r'T.+','')\n",
    "            total_data_copy[_] = pd.to_datetime(total_data_copy[_], format = '%Y-%m-%d', errors='ignore').dt.date\n",
    "        elif _ in total_data:\n",
    "            total_data_copy[_] = pd.to_datetime(total_data_copy[_], format = '%Y-%m-%d', errors='ignore').dt.date\n",
    "            \n",
    "total_data_copy[date_cols].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. `groupby` для объединения значений в строках столбца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_explorations_df = full_explorations_df.merge(full_explorations_df.groupby(['локализация'])['ЛИО'].apply(lambda x: ', '.join(x)).reset_index(),\n",
    "                                                  how='left',\n",
    "                                                  left_on = 'локализация',\n",
    "                                                  right_on = 'локализация')\n",
    "full_explorations_df.sample(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задач из мира Excel\n",
    "\n",
    "[источник](https://habr.com/ru/company/ruvds/blog/500426/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Рукотворные ID:\n",
    "\n",
    "`\n",
    "all_audio['дата рождения2'] = all_audio['дата рождения'].dt.strftime('%d.%m.%Y')\n",
    "all_audio['ФИО_строкой'] = all_audio['фамилия'] + all_audio['имя'] + all_audio['отчество'] + all_audio['дата рождения2']\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace('.','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace(' ','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace('-','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.upper()\n",
    "`\n",
    "\n",
    "#### и удаление дубликатов по сценарию:\n",
    "\n",
    "`rez_true = rez2.sort_values('дата и время приема', ascending=False)\n",
    "rez_true = rez_true.drop_duplicates(subset='idn', keep='first')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Тернарный оператор (конструкция `if`) для создания нового признака/столбца на основе значений уже имеющиегося. Реализация с помощью `list comprehension`:\n",
    "\n",
    "`sales['MoreThan500'] = ['Yes' if x > 500 else 'No' for x in sales['Sales']]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `VLOOKUP (ВПР)`, решается с помощью функции [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html):\n",
    "\n",
    "`sales = pd.merge(sales, states, how='left', on='City')`\n",
    "\n",
    "1. Первый аргумент метода merge — это исходный датафрейм.\n",
    "\n",
    "\n",
    "2. Второй аргумент — это датафрейм, в котором мы ищем значения.\n",
    "\n",
    "\n",
    "3. Аргумент `how` (`left, right, outer, inner`, default=`inner`) указывает на то, как именно мы хотим соединить данные.\n",
    "\n",
    "\n",
    "4. Аргумент `on` указывает на переменную, по которой нужно выполнить соединение (тут ещё можно использовать аргументы `left_on` и `right_on`, нужные в том случае, если интересующие нас данные в разных датафреймах названы по-разному)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pivot table:\n",
    "\n",
    "\n",
    "`sales.pivot_table(index = 'City', values = 'Sales', aggfunc = 'sum')`\n",
    "\n",
    "1. Здесь мы используем метод `sales.pivot_table`, сообщая pandas о том, что мы хотим создать сводную таблицу, основанную на датафрейме sales.\n",
    "\n",
    "\n",
    "2. Аргумент `index` указывает на столбец, по которому мы хотим агрегировать данные.\n",
    "\n",
    "\n",
    "3. Аргумент `values` указывает на то, какие значения мы собираемся агрегировать.\n",
    "\n",
    "\n",
    "4. Аргумент `aggfunc` задаёт функцию, которую мы хотим использовать при обработке значений (`mean, max, min...`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. [Styling](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Заменить PowerQwery:\n",
    "\n",
    "**было:** входящий формат данных (один айди - несколькострок, меняются 2 последних признака)\n",
    "<img src=\"photo_2020-05-27_12-16-44.jpg\" style=\"width: 1000px\"/>\n",
    "\n",
    "\n",
    "**стало:** сделать сводную по дате на признак динамики\n",
    "<img src=\"photo_2020-05-27_12-16-52.jpg\" style=\"width: 1000px\"/>\n",
    "    \n",
    "    \n",
    "    \n",
    "`\n",
    "table = pd.pivot_table(a,\n",
    "                       values=['статус пациента', 'Динамика заболевания'],\n",
    "                       index=['сцепка', 'id_emias','полис омс'],\n",
    "                       lumns=['Дата звонка'], aggfunc=lambda x: ' '.join(x),\n",
    "                       aggfunc='first') #если на пересечении только одно текстовое значение\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. [Смещение данных `shift`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html)\n",
    "\n",
    "\n",
    "Есть DataFrame. Есть колонка Date, и 2 колонки со значениями Col1 и Col2.\n",
    "Задача: нужно запилить колонку Col3, которая в случае, если значение col1 == 1 и col2 == 1  (тут я все сделал, это просто), либо если значение из df['col2'].iloc[x]  == 1 и df['col1'].iloc[x+1] == 1, то проставляется 1 в Col3.\n",
    "\n",
    "\n",
    "**Пример: в таблице ниже за 01/05/20 в Col2 стоит 1,  а за 01/06/20 в Col1 стоит 1, то нужно в новой колонке Col3 поставить 1 на дате 01/05/20.**\n",
    "\n",
    "\n",
    "<img src=\"3th.jpg\" style=\"width: 400px\"/>\n",
    "\n",
    "\n",
    "`if df['col1']== 1 and  df['col2'].shift(1) ==1: 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. `crosstab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. drop-down list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wb = Workbook()\n",
    "ws_zero = wb.active\n",
    "\n",
    "for r in dataframe_to_rows(bullets, index=False, header=False):\n",
    "    ws_zero.append(r)\n",
    "\n",
    "test_list = list(ws_zero.values)\n",
    "true_valid_list = []\n",
    "for _ in test_list:\n",
    "    _ = list(filter(None.__ne__, _))\n",
    "    true_valid_list.append(_)\n",
    "    \n",
    "ws = wb.create_sheet('New Sheet')\n",
    "\n",
    "# make header\n",
    "for number in range(1,len(true_input_col_name)+1):\n",
    "    ws.cell(row=1,column=number,value=true_input_col_name[number-1])\n",
    "\n",
    "# filling position in MTZ - floor\n",
    "for num, key in enumerate(mtz_df['этаж'].tolist()):\n",
    "    ws.cell(row=num+2,column=1,value=key)\n",
    "    \n",
    "# filling position in MTZ - position\n",
    "for num, key in enumerate(mtz_df['ПОЗИЦИЯ'].tolist()):\n",
    "    ws.cell(row=num+2,column=2,value=key)   \n",
    "\n",
    "# filling position in MTZ - position number\n",
    "for num, key in enumerate(mtz_df['ПО_ПЕРЕЧНЮ'].tolist()):\n",
    "    ws.cell(row=num+2,column=3,value=key)  \n",
    "    \n",
    "# filling position in MTZ - items\n",
    "for num, key in enumerate(mtz_df['НАИМЕНОВАНИЕ'].tolist()):\n",
    "    ws.cell(row=num+2,column=4,value=key)\n",
    "\n",
    "# #############################################################\n",
    "# ws_new = wb.create_sheet('New Sheet_new')\n",
    "\n",
    "# data_val = DataValidation(type=\"list\",formula1='=Sheet!$1:$1') #You can change =$A:$A with a smaller range like =A1:A9\n",
    "# ws_new.add_data_validation(data_val)\n",
    "\n",
    "# data_val.add(ws_new[\"B1\"]) #If you go to the cell B1 you will find a drop down list with all the values from the column A    \n",
    "\n",
    "str_from_key = ''\n",
    "# filling DataValidation in MTZ\n",
    "for num, key in enumerate(true_valid_list):\n",
    "    str_from_key = ','.join(key)\n",
    "    data_val = DataValidation(type=\"list\", formula1=str_from_key, allow_blank=True)\n",
    "    ws_zero.add_data_validation(data_val)\n",
    "    data_val.add(ws[f'E{num+2}'])\n",
    "    \n",
    "    \n",
    "# from openpyxl.utils import quote_sheetname\n",
    "# dv = DataValidation(type=\"list\",\n",
    "#                     formula1=\"Sheet!$1:$1\".format(quote_sheetname('Sheet')))\n",
    "    \n",
    "    \n",
    "# for _ in list(compare_dict.keys()):\n",
    "#     for num, key in enumerate(compare_dict.keys()):\n",
    "#         data_val = DataValidation(type=\"list\",formula1=compare_dict[key])\n",
    "#         ws.cell(row=num+2,column=4,value=key)\n",
    "        \n",
    "# ws.cell(column=1, row=new_line_num, value=row[0].value)\n",
    "\n",
    "# data_val = DataValidation(type=\"list\",formula1='=$A:$A') #You can change =$A:$A with a smaller range like =A1:A9\n",
    "# ws.add_data_validation(data_val)\n",
    "# data_val.add(ws[\"B1\"])\n",
    "        \n",
    "wb.save('Test_01_v_18.09.2021.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускорения расчетов `pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем среднюю длину слова\n",
    "def mean_word_len(line):\n",
    "    count = [len(i) for i in line.split()]\n",
    "    res = sum(count) / len(count)\n",
    "    return res\n",
    "\n",
    "def compute_avg_word(df):\n",
    "    return df['words'].apply(mean_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_avg_word(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Multiprocessing (default pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# поределяем кол-во ядер процессора\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_parallel(df, func):\n",
    "    # делим датафрейм на части\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    # считаем метрики для каждого и соединяем обратно\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit apply_parallel(new_df, compute_avg_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ускорение в 2-3 раза;\n",
    "\n",
    "\n",
    "* Использовать распараллеливание на маленьких данных — плохая идея, т.к накладные расходы на межпроцессорное взаимодействие превышают выигрыш по времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим 2-ую таблицу в 100 000 строк и 4 колонки, заполненную случайными числами от 0 до 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4368690868169883"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104818 / 239930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0,100,size=(100000, 4)),columns=['a', 'b', 'c', 'd'])\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для создания новой колонки\n",
    "def multiply(x):\n",
    "    return x * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.6 ms ± 8.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# наша функция\n",
    "%timeit df2['new_col'] = df2['a'].apply(multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 24.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# встроенная имплементация Pandas\n",
    "%timeit df2['new_col'] = df2['a'] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возводим значения строки в квадрат и берем их среднее \n",
    "def square_mean(row):\n",
    "    row = np.power(row, 2)\n",
    "    return np.mean(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in power\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.8 s ± 3.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# применение:\n",
    "%timeit df2['new_col'] = df.apply(square_mean, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  [`numba`](https://habr.com/ru/post/503726/)\n",
    "\n",
    "* Возможно добиться ускорения в тысячи раз;\n",
    "\n",
    "\n",
    "* Можно использовать далеко не везде, в основном для оптимизации математических операций;\n",
    "\n",
    "\n",
    "* Поддерживает не все возможности `python` и `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767 µs ± 350 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# наша функция с оптимизированная `numba`\n",
    "@numba.vectorize\n",
    "def multiply_numba(x):\n",
    "    return x * 5\n",
    "\n",
    "# мы отдаем весь вектор значений, чтобы numba сам провел оптимизацию цикла\n",
    "%timeit df2['new_col'] = multiply_numba(df2['a'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numba не умеет работать с примитивами pandas (Dataframe, Series и тд.)\n",
    "# поэтому мы даем ей двумерный массив numpy\n",
    "@numba.njit\n",
    "def square_mean_numba(arr):\n",
    "    res = np.empty(arr.shape[0])\n",
    "    arr = np.power(arr, 2)\n",
    "    for i in range(arr.shape[0]):\n",
    "        res[i] = np.mean(arr[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# применение:\n",
    "%timeit df['new_col'] = square_mean_numba(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [`pandarallel`](https://habr.com/ru/post/498904/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Выполним данную задачу](#create_df)[<font color='red'> функциями `pandarallel`:</font>](https://github.com/nalepae/pandarallel/blob/master/docs/examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"sample-word\"] = df.sample_column.parallel_apply(function_to_apply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
