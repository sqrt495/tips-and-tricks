{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Contents:</center><a class=\"anchor\" id=\"contents\"></a>\n",
    "\n",
    "1. [Read & Import data](#import)\n",
    "\n",
    "*1.1. Create random DataFrame*\n",
    "\n",
    "2. [Merge, join, concatenate](#join)\n",
    "\n",
    "2. [Analysis](#analysis)\n",
    "\n",
    "3. [Computing acceleration and preprocessing](#preprocessing)\n",
    "\n",
    "4. [Other](#other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Import data\n",
    "<a class=\"anchor\" id=\"import\"></a>\n",
    "\n",
    "[оглавление](#contents) | [дальше>](#join)\n",
    "\n",
    "Some topics:\n",
    "\n",
    "[How upload to notebook files from github (medium.com)](https://medium.com/towards-entrepreneurship/importing-a-csv-file-from-github-in-a-jupyter-notebook-e2c28e7e74a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df = pd.DataFrame(np.random.randint(0, 100, size=(1000, 4)),\n",
    "                                 columns=['a', 'b', 'c', 'd'])\n",
    "random_created_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   a       1000 non-null   int32\n",
      " 1   b       1000 non-null   int32\n",
      " 2   c       1000 non-null   int32\n",
      " 3   d       1000 non-null   int32\n",
      "dtypes: int32(4)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "random_created_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>50.733</td>\n",
       "      <td>28.460353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>75.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>48.383</td>\n",
       "      <td>28.349321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>49.293</td>\n",
       "      <td>29.459243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>48.317</td>\n",
       "      <td>29.267304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>73.25</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count    mean        std  min   25%   50%    75%   max\n",
       "a  1000.0  50.733  28.460353  0.0  28.0  51.5  75.00  99.0\n",
       "b  1000.0  48.383  28.349321  0.0  23.0  49.0  72.00  99.0\n",
       "c  1000.0  49.293  29.459243  0.0  24.0  49.0  75.00  99.0\n",
       "d  1000.0  48.317  29.267304  0.0  22.0  47.0  73.25  99.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insert 10% NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   a       888 non-null    float64\n",
      " 1   b       902 non-null    float64\n",
      " 2   c       876 non-null    float64\n",
      " 3   d       907 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "random_created_df = random_created_df.mask(np.random.random(random_created_df.shape) < .1)\n",
    "random_created_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>888.0</td>\n",
       "      <td>50.467342</td>\n",
       "      <td>28.547535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.75</td>\n",
       "      <td>51.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>902.0</td>\n",
       "      <td>48.034368</td>\n",
       "      <td>28.490627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>876.0</td>\n",
       "      <td>49.795662</td>\n",
       "      <td>29.675818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>907.0</td>\n",
       "      <td>48.378170</td>\n",
       "      <td>29.223869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       mean        std  min    25%   50%   75%   max\n",
       "a  888.0  50.467342  28.547535  0.0  27.75  51.0  75.0  99.0\n",
       "b  902.0  48.034368  28.490627  0.0  23.00  48.0  72.0  99.0\n",
       "c  876.0  49.795662  29.675818  0.0  24.00  50.0  75.0  99.0\n",
       "d  907.0  48.378170  29.223869  0.0  22.00  47.0  74.0  99.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add column with random text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4354\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \"\"\"\n\u001b[1;32m-> 4356\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4358\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1090\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1093\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mfunction_to_apply\u001b[1;34m(i)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def function_to_apply(i):\n",
    "    first = requests.get(f'https://random-word-api.herokuapp.com/word').json() # Random Word API\n",
    "    \n",
    "#     add word\n",
    "#     second = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "#     third = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "\n",
    "    return first[0]\n",
    "#     return \" \".join([first[0], second[0], third[0]])\n",
    "\n",
    "random_created_df['words'] = random_created_df['d'].apply(function_to_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>8.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a     b     c     d\n",
       "488  16.0  20.0  38.0  99.0\n",
       "394   8.0  88.0  48.0  67.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge, join, concatenate\n",
    "<a class=\"anchor\" id=\"join\"></a>\n",
    "\n",
    "[<назад](#import) | [оглавление](#contents) | [дальше>](#analysis)\n",
    "\n",
    "Some topics:\n",
    "\n",
    "[Работа с большими наборами данных](https://habr.com/ru/company/ruvds/blog/442516/)\n",
    "\n",
    "[Управление памятью](https://habr.com/ru/company/mailru/blog/336156/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue few tables to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# показать путь к текщей директории\n",
    "os.getcwd()\n",
    "\n",
    "# указываем путь к папке с файлами, которые хотим объединить\n",
    "\n",
    "folder = r'C:\\\\Users\\\\Asus\\\\GKU\\\\2505\\\\all_audio' # insert abs path\n",
    "\n",
    "# создаем список с названиями файлов\n",
    "files_names = os.listdir(folder)\n",
    "\n",
    "#формируем список путей к файлам\n",
    "files = [os.path.join(folder,f) for f in files_names] \n",
    "\n",
    "all_file_frames = [] #сюда будем добавлять прочитанную таблицу \n",
    "\n",
    "# цикл сборки таблиц в список\n",
    "for f in files:\n",
    "    print('Reading %s'%f)\n",
    "    tab = pd.read_excel(f)\n",
    "    all_file_frames.append(tab)\n",
    "\n",
    "# склеиваем все таблицы в списке\n",
    "all_frame = pd.concat(all_file_frames,axis=0) #  axis=0 если нужно добавить таблицу снизу и axis=1 если нужно слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Pandas Column Names to Lower Case\n",
    "\n",
    "df= df.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "<a class=\"anchor\" id=\"analysis\"></a>\n",
    "\n",
    "[<назад](#join) | [оглавление](#contents) | [дальше>](#preprocessing)\n",
    "\n",
    "Some topics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing acceleration and preprocessing\n",
    "<a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "[<назад](#analysis) | [оглавление](#contents)\n",
    "\n",
    "Some topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    998\n",
       "True       2\n",
       "Name: equal 4th, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find rows with equal values\n",
    "random_created_df['equal 4th'] =  random_created_df.iloc[:,0:5].nunique(axis = 1).eq(1)\n",
    "random_created_df['equal 4th'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some values to  1\n",
    "\n",
    "for n in list(range(1,1001)):\n",
    "    if n % 5 == 0:\n",
    "        random_created_df.loc[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    800\n",
       "True     201\n",
       "Name: equal 4th, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df['equal 4th'] =  random_created_df.iloc[:,0:5].nunique(axis = 1).eq(1)\n",
    "random_created_df['equal 4th'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всем добрый день!\n",
    "# Помогите решить задачку. Имею следующий формат учета продаж.\n",
    "# Необходимо посчитать тотал по каждому клиенту. \n",
    "# В Power Query задачку решил, в питоне не получается.\n",
    "\n",
    "\n",
    "# df = pd.read_excel('/.../Новая таблица.xlsx')\n",
    "# pd.DataFrame.from_records(\n",
    "#     df.apply(lambda x: {value:x[idx+1] for idx, (col_name, value) in enumerate(zip(df.columns, x)) if 'customer' in col_name.lower()}, axis=1).values\n",
    "#     ).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.eq(report.iloc[:,5:10], axis=0).all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create custom describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк в наборе данных: 100000\n",
      "\n",
      "10% - доля пропусков в столбце c\n",
      "9% - доля пропусков в столбце d\n",
      "9% - доля пропусков в столбце a\n",
      "9% - доля пропусков в столбце b\n"
     ]
    }
   ],
   "source": [
    "w_df = random_created_df.copy()\n",
    "\n",
    "show_percent_dict = {}\n",
    "\n",
    "for _ in w_df.columns.tolist():\n",
    "    percent = (w_df[w_df[_].isna()].shape[0] / w_df.shape[0]) * 100\n",
    "    show_percent_dict[_] = percent\n",
    "\n",
    "show_percent_dict = dict(sorted(show_percent_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "print(f'Всего строк в наборе данных: {w_df.shape[0]}\\n')\n",
    "\n",
    "for k,v in show_percent_dict.items():  \n",
    "    v = str(int(v)) + '%'\n",
    "    print(f'{v} - доля пропусков в столбце {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to date from string\n",
    "\n",
    "# нормализуем и форматируем все даты\n",
    "datecols = [col for col in pp.columns if re.search('(?i)Дат(а|у)', col)]\n",
    "gooddatecols = []\n",
    "baddatecols = []\n",
    "for datecol in datecols:\n",
    "  if pp[datecol].dtypes == 'datetime64[ns]':\n",
    "    gooddatecols.append(datecol)\n",
    "  else:\n",
    "    baddatecols.append(datecol)\n",
    "    \n",
    "def normalize_date(series):\n",
    "  def trydate(arg):\n",
    "    try:\n",
    "      if pd.isna(arg): return pd.NaT\n",
    "      if type(arg) == datetime.datetime:\n",
    "        return pd.to_datetime(arg).normalize()\n",
    "      elif type(arg) == str:\n",
    "        match = re.search(r'\\d{2}(.)\\d{2}\\1\\d{4}', arg)\n",
    "        if match:\n",
    "          delimiter = match.group(1)\n",
    "          try: return pd.to_datetime(match.group(), format=f'%d{delimiter}%m{delimiter}%Y')\n",
    "          except: return False\n",
    "        else: return arg\n",
    "    except: \n",
    "      return False\n",
    "  if series.name in gooddatecols:\n",
    "    return series.dt.normalize()\n",
    "  else:\n",
    "    return series.apply(trydate)\n",
    "\n",
    "for datecol in datecols:\n",
    "  pp[datecol] = normalize_date(pp[datecol])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "for _ in all_frame.columns.tolist():\n",
    "    if 'Дата' in _:\n",
    "        all_frame[_] = pd.to_datetime(all_frame[_], errors='ignore') \n",
    "\n",
    "all_frame.to_excel(f'направления_к_онколгу_из_облака_BD_1194_на_ОТ_РАЗРАБОВ_{today}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение и быстрое преобразование данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. `value_counts` и `select_dtypes` сэкономит кучу времени:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `df.dtypes.value_counts()`\n",
    "\n",
    "\n",
    "* `df.select_dtypes(include = ['float64', 'int64'])`\n",
    "\n",
    "Полезные аргументы `value_counts`:\n",
    "\n",
    "* `normalize = True` – проверить частоту вместо подсчёта.\n",
    "\n",
    "\n",
    "* `dropna = False` – включить пропущенные значения в статистику.\n",
    "\n",
    "\n",
    "* `df['c'].value_counts().reset_index()` – преобразовать таблицу статистики в объект Pandas DataFrame.\n",
    "\n",
    "\n",
    "* `df['c'].value_counts().reset_index().sort_values(by='index')` – показывать статистику, отсортированную по уникальным значениям в столбце 'c' вместо количества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `map` - команда для простого преобразования данных.\n",
    "Определяете словарь, в котором «ключами» являются старые значения, а «значениями» – новые значения:\n",
    "\n",
    "`level_map = {1: 'high', 2: 'medium', 3: 'low'}`\n",
    "\n",
    "`df['c_level'] = df['c'].map(level_map)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Как это использовать?</font>\n",
    "\n",
    "`all_doc.applymap(type)['BIRTH_DATE'].value_counts()\n",
    "bad = all_doc[all_doc['BIRTH_DATE'].map(lambda x: type(x) == str)]\n",
    "good = all_doc[all_doc['BIRTH_DATE'].map(lambda x: type(x) != str)]\n",
    "all_doc_2 = bad.append(good, ignore_index=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.  Выборка и фильтрация:\n",
    "\n",
    "конечно можно решать задачи через `loc` `iloc`\n",
    "\n",
    "`data.loc[:,\"User\"]`\n",
    "\n",
    "`data.iloc[:5,0]`\n",
    "\n",
    "В SQL используем SELECT * FROM… WHERE ID в («A001», «C022»,…) и получаем записи с конкретными идентификаторами. Если хотите сделать то же с помощью Python библиотеки Pandas, используйте:\n",
    "\n",
    "\n",
    "`df_filter = df['ID'].isin(['A001','C022',...])`\n",
    "\n",
    "`df[df_filter]`\n",
    "\n",
    "\n",
    "#### 3.2. [numpy.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html) для работы со значениями:\n",
    "\n",
    "`numpy.where(data['Revenue']>400,1,0)`\n",
    "\n",
    "`numpy.where(data['Revenue']<data['Expense'],1,2)`\n",
    "\n",
    "#### [3.3. Еще 3 полезных метода](https://m.habr.com/ru/company/ruvds/blog/479276/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задач из мира Excel\n",
    "\n",
    "[источник](https://habr.com/ru/company/ruvds/blog/500426/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Рукотворные ID:\n",
    "\n",
    "`\n",
    "all_audio['дата рождения2'] = all_audio['дата рождения'].dt.strftime('%d.%m.%Y')\n",
    "all_audio['ФИО_строкой'] = all_audio['фамилия'] + all_audio['имя'] + all_audio['отчество'] + all_audio['дата рождения2']\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace('.','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace(' ','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace('-','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.upper()\n",
    "`\n",
    "\n",
    "#### и удаление дубликатов по сценарию:\n",
    "\n",
    "`rez_true = rez2.sort_values('дата и время приема', ascending=False)\n",
    "rez_true = rez_true.drop_duplicates(subset='idn', keep='first')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Тернарный оператор (конструкция `if`) для создания нового признака/столбца на основе значений уже имеющиегося. Реализация с помощью `list comprehension`:\n",
    "\n",
    "`sales['MoreThan500'] = ['Yes' if x > 500 else 'No' for x in sales['Sales']]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `VLOOKUP (ВПР)`, решается с помощью функции [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html):\n",
    "\n",
    "`sales = pd.merge(sales, states, how='left', on='City')`\n",
    "\n",
    "1. Первый аргумент метода merge — это исходный датафрейм.\n",
    "\n",
    "\n",
    "2. Второй аргумент — это датафрейм, в котором мы ищем значения.\n",
    "\n",
    "\n",
    "3. Аргумент `how` (`left, right, outer, inner`, default=`inner`) указывает на то, как именно мы хотим соединить данные.\n",
    "\n",
    "\n",
    "4. Аргумент `on` указывает на переменную, по которой нужно выполнить соединение (тут ещё можно использовать аргументы `left_on` и `right_on`, нужные в том случае, если интересующие нас данные в разных датафреймах названы по-разному)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pivot table:\n",
    "\n",
    "\n",
    "`sales.pivot_table(index = 'City', values = 'Sales', aggfunc = 'sum')`\n",
    "\n",
    "1. Здесь мы используем метод `sales.pivot_table`, сообщая pandas о том, что мы хотим создать сводную таблицу, основанную на датафрейме sales.\n",
    "\n",
    "\n",
    "2. Аргумент `index` указывает на столбец, по которому мы хотим агрегировать данные.\n",
    "\n",
    "\n",
    "3. Аргумент `values` указывает на то, какие значения мы собираемся агрегировать.\n",
    "\n",
    "\n",
    "4. Аргумент `aggfunc` задаёт функцию, которую мы хотим использовать при обработке значений (`mean, max, min...`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. [Styling](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Заменить PowerQwery:\n",
    "\n",
    "**было:** входящий формат данных (один айди - несколькострок, меняются 2 последних признака)\n",
    "<img src=\"photo_2020-05-27_12-16-44.jpg\" style=\"width: 1000px\"/>\n",
    "\n",
    "\n",
    "**стало:** сделать сводную по дате на признак динамики\n",
    "<img src=\"photo_2020-05-27_12-16-52.jpg\" style=\"width: 1000px\"/>\n",
    "    \n",
    "    \n",
    "    \n",
    "`\n",
    "table = pd.pivot_table(a,\n",
    "                       values=['статус пациента', 'Динамика заболевания'],\n",
    "                       index=['сцепка', 'id_emias','полис омс'],\n",
    "                       lumns=['Дата звонка'], aggfunc=lambda x: ' '.join(x),\n",
    "                       aggfunc='first') #если на пересечении только одно текстовое значение\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. [Смещение данных `shift`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html)\n",
    "\n",
    "\n",
    "Есть DataFrame. Есть колонка Date, и 2 колонки со значениями Col1 и Col2.\n",
    "Задача: нужно запилить колонку Col3, которая в случае, если значение col1 == 1 и col2 == 1  (тут я все сделал, это просто), либо если значение из df['col2'].iloc[x]  == 1 и df['col1'].iloc[x+1] == 1, то проставляется 1 в Col3.\n",
    "\n",
    "\n",
    "**Пример: в таблице ниже за 01/05/20 в Col2 стоит 1,  а за 01/06/20 в Col1 стоит 1, то нужно в новой колонке Col3 поставить 1 на дате 01/05/20.**\n",
    "\n",
    "\n",
    "<img src=\"3th.jpg\" style=\"width: 400px\"/>\n",
    "\n",
    "\n",
    "`if df['col1']== 1 and  df['col2'].shift(1) ==1: 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. `crosstab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускорения расчетов `pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем среднюю длину слова\n",
    "def mean_word_len(line):\n",
    "    count = [len(i) for i in line.split()]\n",
    "    res = sum(count) / len(count)\n",
    "    return res\n",
    "\n",
    "def compute_avg_word(df):\n",
    "    return df['words'].apply(mean_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_avg_word(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Multiprocessing (default pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# поределяем кол-во ядер процессора\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_parallel(df, func):\n",
    "    # делим датафрейм на части\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    # считаем метрики для каждого и соединяем обратно\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit apply_parallel(new_df, compute_avg_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ускорение в 2-3 раза;\n",
    "\n",
    "\n",
    "* Использовать распараллеливание на маленьких данных — плохая идея, т.к накладные расходы на межпроцессорное взаимодействие превышают выигрыш по времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим 2-ую таблицу в 100 000 строк и 4 колонки, заполненную случайными числами от 0 до 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4368690868169883"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104818 / 239930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0,100,size=(100000, 4)),columns=['a', 'b', 'c', 'd'])\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для создания новой колонки\n",
    "def multiply(x):\n",
    "    return x * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.6 ms ± 8.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# наша функция\n",
    "%timeit df2['new_col'] = df2['a'].apply(multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 24.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# встроенная имплементация Pandas\n",
    "%timeit df2['new_col'] = df2['a'] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возводим значения строки в квадрат и берем их среднее \n",
    "def square_mean(row):\n",
    "    row = np.power(row, 2)\n",
    "    return np.mean(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in power\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.8 s ± 3.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# применение:\n",
    "%timeit df2['new_col'] = df.apply(square_mean, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  [`numba`](https://habr.com/ru/post/503726/)\n",
    "\n",
    "* Возможно добиться ускорения в тысячи раз;\n",
    "\n",
    "\n",
    "* Можно использовать далеко не везде, в основном для оптимизации математических операций;\n",
    "\n",
    "\n",
    "* Поддерживает не все возможности `python` и `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767 µs ± 350 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# наша функция с оптимизированная `numba`\n",
    "@numba.vectorize\n",
    "def multiply_numba(x):\n",
    "    return x * 5\n",
    "\n",
    "# мы отдаем весь вектор значений, чтобы numba сам провел оптимизацию цикла\n",
    "%timeit df2['new_col'] = multiply_numba(df2['a'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numba не умеет работать с примитивами pandas (Dataframe, Series и тд.)\n",
    "# поэтому мы даем ей двумерный массив numpy\n",
    "@numba.njit\n",
    "def square_mean_numba(arr):\n",
    "    res = np.empty(arr.shape[0])\n",
    "    arr = np.power(arr, 2)\n",
    "    for i in range(arr.shape[0]):\n",
    "        res[i] = np.mean(arr[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# применение:\n",
    "%timeit df['new_col'] = square_mean_numba(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [`pandarallel`](https://habr.com/ru/post/498904/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Выполним данную задачу](#create_df)[<font color='red'> функциями `pandarallel`:</font>](https://github.com/nalepae/pandarallel/blob/master/docs/examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"sample-word\"] = df.sample_column.parallel_apply(function_to_apply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
