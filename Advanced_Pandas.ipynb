{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>*Contents:* </center><a class=\"anchor\" id=\"contents\"></a>\n",
    "\n",
    "0. [Introduction](#intro)\n",
    "\n",
    "1.1. [Library import, references and data loading](#import)\n",
    "1.2. [Preprocessing](#preprocessing)\n",
    "\n",
    "2. [Fast analysis](#fanalysis)\n",
    "\n",
    "3. [Deep analysis, feature engineering & selection](#da)\n",
    "\n",
    "4.1. [Prediction preparing](#pred)\n",
    "\n",
    "4.2. [Quality metrics](#quality-metrics)\n",
    "\n",
    "5. [Basic Models](#basic_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file from github\n",
    "\n",
    "# https://medium.com/towards-entrepreneurship/importing-a-csv-file-from-github-in-a-jupyter-notebook-e2c28e7e74a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Всем добрый день!\n",
    "Помогите решить задачку. Имею следующий формат учета продаж.\n",
    "Необходимо посчитать тотал по каждому клиенту. \n",
    "В Power Query задачку решил, в питоне не получается.\n",
    "\n",
    "\n",
    "df = pd.read_excel('/.../Новая таблица.xlsx')\n",
    "pd.DataFrame.from_records(\n",
    "    df.apply(lambda x: {value:x[idx+1] for idx, (col_name, value) in enumerate(zip(df.columns, x)) if 'customer' in col_name.lower()}, axis=1).values\n",
    "    ).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create random DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df = pd.DataFrame(np.random.randint(0,100,size=(100000, 4)),columns=['a', 'b', 'c', 'd'])\n",
    "random_created_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   a       100000 non-null  int32\n",
      " 1   b       100000 non-null  int32\n",
      " 2   c       100000 non-null  int32\n",
      " 3   d       100000 non-null  int32\n",
      "dtypes: int32(4)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "random_created_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.501260</td>\n",
       "      <td>49.470450</td>\n",
       "      <td>49.393940</td>\n",
       "      <td>49.598440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.817661</td>\n",
       "      <td>28.886251</td>\n",
       "      <td>28.903641</td>\n",
       "      <td>28.886608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   a              b              c              d\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
       "mean       49.501260      49.470450      49.393940      49.598440\n",
       "std        28.817661      28.886251      28.903641      28.886608\n",
       "min         0.000000       0.000000       0.000000       0.000000\n",
       "25%        24.750000      24.000000      24.000000      24.000000\n",
       "50%        50.000000      49.000000      49.000000      50.000000\n",
       "75%        74.000000      74.000000      74.000000      75.000000\n",
       "max        99.000000      99.000000      99.000000      99.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 10% NaN values\n",
    "random_created_df = random_created_df.mask(np.random.random(random_created_df.shape) < .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   a       90032 non-null  float64\n",
      " 1   b       90050 non-null  float64\n",
      " 2   c       89980 non-null  float64\n",
      " 3   d       90027 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "random_created_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90032.000000</td>\n",
       "      <td>90050.000000</td>\n",
       "      <td>89980.000000</td>\n",
       "      <td>90027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.479318</td>\n",
       "      <td>49.466718</td>\n",
       "      <td>49.398422</td>\n",
       "      <td>49.553967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.808855</td>\n",
       "      <td>28.889509</td>\n",
       "      <td>28.904134</td>\n",
       "      <td>28.859403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  a             b             c             d\n",
       "count  90032.000000  90050.000000  89980.000000  90027.000000\n",
       "mean      49.479318     49.466718     49.398422     49.553967\n",
       "std       28.808855     28.889509     28.904134     28.859403\n",
       "min        0.000000      0.000000      0.000000      0.000000\n",
       "25%       24.000000     24.000000     24.000000     24.000000\n",
       "50%       50.000000     49.000000     50.000000     50.000000\n",
       "75%       74.000000     74.000000     74.000000     75.000000\n",
       "max       99.000000     99.000000     99.000000     99.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_created_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create custom describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк в наборе данных: 100000\n",
      "\n",
      "10% - доля пропусков в столбце c\n",
      "9% - доля пропусков в столбце d\n",
      "9% - доля пропусков в столбце a\n",
      "9% - доля пропусков в столбце b\n"
     ]
    }
   ],
   "source": [
    "w_df = random_created_df.copy()\n",
    "\n",
    "show_percent_dict = {}\n",
    "\n",
    "for _ in w_df.columns.tolist():\n",
    "    percent = (w_df[w_df[_].isna()].shape[0] / w_df.shape[0]) * 100\n",
    "    show_percent_dict[_] = percent\n",
    "\n",
    "show_percent_dict = dict(sorted(show_percent_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "print(f'Всего строк в наборе данных: {w_df.shape[0]}\\n')\n",
    "\n",
    "for k,v in show_percent_dict.items():  \n",
    "    v = str(int(v)) + '%'\n",
    "    print(f'{v} - доля пропусков в столбце {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Склейка выгрузок в общий файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Работа с большими наборами данных](https://habr.com/ru/company/ruvds/blog/442516/) и [<font color='red'>управление памятью. </font>](https://habr.com/ru/company/mailru/blog/336156/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# показать путь к текщей директории\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# указываем путь к папке с файлами, которые хотим объединить\n",
    "folder = r'C:\\\\Users\\\\Asus\\\\GKU\\\\2505\\\\all_audio'\n",
    "# создаем список с названиями файлов\n",
    "files_names = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#формируем список путей к файлам\n",
    "files = [os.path.join(folder,f) for f in files_names] \n",
    "\n",
    "all_file_frames = [] #сюда будем добавлять прочитанную таблицу \n",
    "\n",
    "# цикл сборки таблиц в список\n",
    "for f in files:\n",
    "    print('Reading %s'%f)\n",
    "    tab = pd.read_excel(f)\n",
    "    all_file_frames.append(tab)\n",
    "\n",
    "# склеиваем все таблицы в списке\n",
    "all_frame = pd.concat(all_file_frames,axis=0) #  axis=0 если нужно добавить таблицу снизу и axis=1 если нужно слева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение и быстрое преобразование данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. `value_counts` и `select_dtypes` сэкономит кучу времени:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `df.dtypes.value_counts()`\n",
    "\n",
    "\n",
    "* `df.select_dtypes(include = ['float64', 'int64'])`\n",
    "\n",
    "Полезные аргументы `value_counts`:\n",
    "\n",
    "* `normalize = True` – проверить частоту вместо подсчёта.\n",
    "\n",
    "\n",
    "* `dropna = False` – включить пропущенные значения в статистику.\n",
    "\n",
    "\n",
    "* `df['c'].value_counts().reset_index()` – преобразовать таблицу статистики в объект Pandas DataFrame.\n",
    "\n",
    "\n",
    "* `df['c'].value_counts().reset_index().sort_values(by='index')` – показывать статистику, отсортированную по уникальным значениям в столбце 'c' вместо количества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `map` - команда для простого преобразования данных.\n",
    "Определяете словарь, в котором «ключами» являются старые значения, а «значениями» – новые значения:\n",
    "\n",
    "`level_map = {1: 'high', 2: 'medium', 3: 'low'}`\n",
    "\n",
    "`df['c_level'] = df['c'].map(level_map)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Как это использовать?</font>\n",
    "\n",
    "`all_doc.applymap(type)['BIRTH_DATE'].value_counts()\n",
    "bad = all_doc[all_doc['BIRTH_DATE'].map(lambda x: type(x) == str)]\n",
    "good = all_doc[all_doc['BIRTH_DATE'].map(lambda x: type(x) != str)]\n",
    "all_doc_2 = bad.append(good, ignore_index=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.  Выборка и фильтрация:\n",
    "\n",
    "конечно можно решать задачи через `loc` `iloc`\n",
    "\n",
    "`data.loc[:,\"User\"]`\n",
    "\n",
    "`data.iloc[:5,0]`\n",
    "\n",
    "В SQL используем SELECT * FROM… WHERE ID в («A001», «C022»,…) и получаем записи с конкретными идентификаторами. Если хотите сделать то же с помощью Python библиотеки Pandas, используйте:\n",
    "\n",
    "\n",
    "`df_filter = df['ID'].isin(['A001','C022',...])`\n",
    "\n",
    "`df[df_filter]`\n",
    "\n",
    "\n",
    "#### 3.2. [numpy.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html) для работы со значениями:\n",
    "\n",
    "`numpy.where(data['Revenue']>400,1,0)`\n",
    "\n",
    "`numpy.where(data['Revenue']<data['Expense'],1,2)`\n",
    "\n",
    "#### [3.3. Еще 3 полезных метода](https://m.habr.com/ru/company/ruvds/blog/479276/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задач из мира Excel\n",
    "\n",
    "[источник](https://habr.com/ru/company/ruvds/blog/500426/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Рукотворные ID:\n",
    "\n",
    "`\n",
    "all_audio['дата рождения2'] = all_audio['дата рождения'].dt.strftime('%d.%m.%Y')\n",
    "all_audio['ФИО_строкой'] = all_audio['фамилия'] + all_audio['имя'] + all_audio['отчество'] + all_audio['дата рождения2']\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace('.','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace(' ','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.replace('-','',regex=False)\n",
    "all_audio['ФИО_строкой'] = all_audio['ФИО_строкой'].str.upper()\n",
    "`\n",
    "\n",
    "#### и удаление дубликатов по сценарию:\n",
    "\n",
    "`rez_true = rez2.sort_values('дата и время приема', ascending=False)\n",
    "rez_true = rez_true.drop_duplicates(subset='idn', keep='first')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Тернарный оператор (конструкция `if`) для создания нового признака/столбца на основе значений уже имеющиегося. Реализация с помощью `list comprehension`:\n",
    "\n",
    "`sales['MoreThan500'] = ['Yes' if x > 500 else 'No' for x in sales['Sales']]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `VLOOKUP (ВПР)`, решается с помощью функции [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html):\n",
    "\n",
    "`sales = pd.merge(sales, states, how='left', on='City')`\n",
    "\n",
    "1. Первый аргумент метода merge — это исходный датафрейм.\n",
    "\n",
    "\n",
    "2. Второй аргумент — это датафрейм, в котором мы ищем значения.\n",
    "\n",
    "\n",
    "3. Аргумент `how` (`left, right, outer, inner`, default=`inner`) указывает на то, как именно мы хотим соединить данные.\n",
    "\n",
    "\n",
    "4. Аргумент `on` указывает на переменную, по которой нужно выполнить соединение (тут ещё можно использовать аргументы `left_on` и `right_on`, нужные в том случае, если интересующие нас данные в разных датафреймах названы по-разному)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pivot table:\n",
    "\n",
    "\n",
    "`sales.pivot_table(index = 'City', values = 'Sales', aggfunc = 'sum')`\n",
    "\n",
    "1. Здесь мы используем метод `sales.pivot_table`, сообщая pandas о том, что мы хотим создать сводную таблицу, основанную на датафрейме sales.\n",
    "\n",
    "\n",
    "2. Аргумент `index` указывает на столбец, по которому мы хотим агрегировать данные.\n",
    "\n",
    "\n",
    "3. Аргумент `values` указывает на то, какие значения мы собираемся агрегировать.\n",
    "\n",
    "\n",
    "4. Аргумент `aggfunc` задаёт функцию, которую мы хотим использовать при обработке значений (`mean, max, min...`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. [Styling](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Заменить PowerQwery:\n",
    "\n",
    "**было:** входящий формат данных (один айди - несколькострок, меняются 2 последних признака)\n",
    "<img src=\"photo_2020-05-27_12-16-44.jpg\" style=\"width: 1000px\"/>\n",
    "\n",
    "\n",
    "**стало:** сделать сводную по дате на признак динамики\n",
    "<img src=\"photo_2020-05-27_12-16-52.jpg\" style=\"width: 1000px\"/>\n",
    "    \n",
    "    \n",
    "    \n",
    "`\n",
    "table = pd.pivot_table(a,\n",
    "                       values=['статус пациента', 'Динамика заболевания'],\n",
    "                       index=['сцепка', 'id_emias','полис омс'],\n",
    "                       lumns=['Дата звонка'], aggfunc=lambda x: ' '.join(x),\n",
    "                       aggfunc='first') #если на пересечении только одно текстовое значение\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. [Смещение данных `shift`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html)\n",
    "\n",
    "\n",
    "Есть DataFrame. Есть колонка Date, и 2 колонки со значениями Col1 и Col2.\n",
    "Задача: нужно запилить колонку Col3, которая в случае, если значение col1 == 1 и col2 == 1  (тут я все сделал, это просто), либо если значение из df['col2'].iloc[x]  == 1 и df['col1'].iloc[x+1] == 1, то проставляется 1 в Col3.\n",
    "\n",
    "\n",
    "**Пример: в таблице ниже за 01/05/20 в Col2 стоит 1,  а за 01/06/20 в Col1 стоит 1, то нужно в новой колонке Col3 поставить 1 на дате 01/05/20.**\n",
    "\n",
    "\n",
    "<img src=\"3th.jpg\" style=\"width: 400px\"/>\n",
    "\n",
    "\n",
    "`if df['col1']== 1 and  df['col2'].shift(1) ==1: 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. `crosstab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускорения расчетов `pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создаем и обрабатываем таблицу средствами `pandas`:**\n",
    "<a class=\"anchor\" id=\"create_df\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем таблицу из 10 строк и одного столбца\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [i for i in range(10)],\n",
    "    columns=[\"sample_column\"]\n",
    ")\n",
    "\n",
    "# используем запрос к рандомайзеру слов чтобы вернуть последовательность из 3-х слов\n",
    "\n",
    "def function_to_apply(i):\n",
    "    first = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "    second = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "    third = requests.get(f'https://random-word-api.herokuapp.com/word').json()\n",
    "\n",
    "    return \" \".join([first[0], second[0], third[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.09it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.07it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.06it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.08it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.03it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.09it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.06it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.67 s ± 170 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# с помощь стандартных средств `pandas` добавим столбец со словами:\n",
    "\n",
    "# progress_apply = apply + tqdm\n",
    "%timeit df[\"words\"] = df.sample_column.progress_apply(function_to_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_column</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>campo emulsify boinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>indenes documentations bamboos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bicaudal integrand immingle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tabbying hecks treenail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dermabrasions tissues apoapsides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>urologic outdragging cogitos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>avocational ochrous walkings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>deliberatively shiploads quiffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>synecologies partiality propitiations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>shillelagh astarboard minutest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_column                                  words\n",
       "0              0                  campo emulsify boinks\n",
       "1              1         indenes documentations bamboos\n",
       "2              2            bicaudal integrand immingle\n",
       "3              3                tabbying hecks treenail\n",
       "4              4       dermabrasions tissues apoapsides\n",
       "5              5           urologic outdragging cogitos\n",
       "6              6           avocational ochrous walkings\n",
       "7              7        deliberatively shiploads quiffs\n",
       "8              8  synecologies partiality propitiations\n",
       "9              9         shillelagh astarboard minutest"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# увеличиваю датасет в 100 раз, добавляя копии в конец\n",
    "new_df = pd.concat([df] * 100, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем среднюю длину слова\n",
    "def mean_word_len(line):\n",
    "    count = [len(i) for i in line.split()]\n",
    "    res = sum(count) / len(count)\n",
    "    return res\n",
    "\n",
    "def compute_avg_word(df):\n",
    "    return df['words'].apply(mean_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_avg_word(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Multiprocessing (default pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# поределяем кол-во ядер процессора\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_parallel(df, func):\n",
    "    # делим датафрейм на части\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    # считаем метрики для каждого и соединяем обратно\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit apply_parallel(new_df, compute_avg_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ускорение в 2-3 раза;\n",
    "\n",
    "\n",
    "* Использовать распараллеливание на маленьких данных — плохая идея, т.к накладные расходы на межпроцессорное взаимодействие превышают выигрыш по времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим 2-ую таблицу в 100 000 строк и 4 колонки, заполненную случайными числами от 0 до 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4368690868169883"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104818 / 239930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0,100,size=(100000, 4)),columns=['a', 'b', 'c', 'd'])\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для создания новой колонки\n",
    "def multiply(x):\n",
    "    return x * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.6 ms ± 8.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# наша функция\n",
    "%timeit df2['new_col'] = df2['a'].apply(multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 24.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# встроенная имплементация Pandas\n",
    "%timeit df2['new_col'] = df2['a'] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возводим значения строки в квадрат и берем их среднее \n",
    "def square_mean(row):\n",
    "    row = np.power(row, 2)\n",
    "    return np.mean(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in power\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.8 s ± 3.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# применение:\n",
    "%timeit df2['new_col'] = df.apply(square_mean, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  [`numba`](https://habr.com/ru/post/503726/)\n",
    "\n",
    "* Возможно добиться ускорения в тысячи раз;\n",
    "\n",
    "\n",
    "* Можно использовать далеко не везде, в основном для оптимизации математических операций;\n",
    "\n",
    "\n",
    "* Поддерживает не все возможности `python` и `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767 µs ± 350 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# наша функция с оптимизированная `numba`\n",
    "@numba.vectorize\n",
    "def multiply_numba(x):\n",
    "    return x * 5\n",
    "\n",
    "# мы отдаем весь вектор значений, чтобы numba сам провел оптимизацию цикла\n",
    "%timeit df2['new_col'] = multiply_numba(df2['a'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numba не умеет работать с примитивами pandas (Dataframe, Series и тд.)\n",
    "# поэтому мы даем ей двумерный массив numpy\n",
    "@numba.njit\n",
    "def square_mean_numba(arr):\n",
    "    res = np.empty(arr.shape[0])\n",
    "    arr = np.power(arr, 2)\n",
    "    for i in range(arr.shape[0]):\n",
    "        res[i] = np.mean(arr[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# применение:\n",
    "%timeit df['new_col'] = square_mean_numba(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [`pandarallel`](https://habr.com/ru/post/498904/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Выполним данную задачу](#create_df)[<font color='red'> функциями `pandarallel`:</font>](https://github.com/nalepae/pandarallel/blob/master/docs/examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"sample-word\"] = df.sample_column.parallel_apply(function_to_apply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
